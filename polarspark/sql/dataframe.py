import polars as pl
from typing import List, Union, Any, Tuple
from .column import Column

class DataFrame:
    def __init__(self, df: pl.DataFrame):
        self._df = df
        self._alias = None
        self._left_ref = None
        self._right_ref = None
        self._left_alias = None
        self._right_alias = None
        self._left_cols = None
        self._right_cols = None




    def __getitem__(self, item: str) -> Column:
        if isinstance(item, str):
            # Check for alias prefix in string selection
            if self._alias and item.startswith(f"{self._alias}."):
                item = item[len(self._alias)+1:]
            
            c = Column(pl.col(item))
            c._is_simple_col = True
            c._col_name = item
            # Store a reference to the df to help with ambiguous joins
            c._df_ref = id(self)
            c._table_name = self._alias
            return c


        raise ValueError(f"Unsupported item type: {type(item)}")

    def __getattr__(self, name: str) -> Column:
        if name in self.columns:
            return self[name]
        raise AttributeError(f"'DataFrame' object has no attribute '{name}'")

    def select(self, *cols: Union[str, Column, List[Union[str, Column]]]) -> "DataFrame":

        normalized_cols = []
        for c in cols:
            if isinstance(c, list):
                normalized_cols.extend(c)
            else:
                normalized_cols.append(c)
        
        exprs = []
        cols_in_df = self.columns
        for c in normalized_cols:
            if isinstance(c, str):
                from .functions import col
                # Use col() to handle dot parsing (table.col.field)
                c = col(c)


            if isinstance(c, Column):
                # Resolve using context (id, alias, columns)
                # If not a join result, left_cols is simply current columns
                exprs.append(c._resolve(
                    self._left_ref, self._right_ref, 
                    self._left_alias, self._right_alias,
                    self._left_cols or self.columns, 
                    self._right_cols
                ))




            else:
                raise ValueError(f"Unsupported column type: {type(c)}")
        
        df = self._df.select(exprs)

        
        # If any was a generator, we might need to unnest.
        # This is a bit hacky. Let's look for struct columns and unnest them if they look like they came from generators.
        # Actually, let's just use unnest if the resulting df has struct columns that were just created?
        # A more reliable way is to check the Column objects we just used.
        for c in normalized_cols:
            if isinstance(c, Column) and hasattr(c, "_is_generator") and c._is_generator:
                # Find the name in the resulting df
                # This is tricky without knowing the exact output name.
                # For posexplode in my test, it's unnamed or autogenerated.
                # Let's unnest ALL columns that are structs for now? No.
                # Let's try to unnest by checking the dtypes.
                struct_cols = [name for name, dtype in zip(df.columns, df.dtypes) if dtype == pl.Struct]
                if struct_cols:
                    df = df.unnest(struct_cols)
        
        return DataFrame(df)


    def filter(self, condition: Union[str, Column]) -> "DataFrame":
        if isinstance(condition, str):
            # Polars' query engine doesn't exactly match Spark's SQL strings, 
            # but for simple cases it might work or we might need a parser.
            # Keeping it simple and assuming it's a column name or we can't support complex SQL yet.
            raise NotImplementedError("String conditions in filter are not yet supported. Use Column expressions.")
        
        return DataFrame(self._df.filter(condition._expr))

    def where(self, condition: Union[str, Column]) -> "DataFrame":
        return self.filter(condition)

    def withColumn(self, name: str, col: Column) -> "DataFrame":
        return DataFrame(self._df.with_columns(col._expr.alias(name)))

    def withColumnRenamed(self, existing: str, new: str) -> "DataFrame":
        return DataFrame(self._df.rename({existing: new}))

    def distinct(self) -> "DataFrame":
        return DataFrame(self._df.unique())

    def drop(self, *cols: str) -> "DataFrame":

        return DataFrame(self._df.drop(list(cols)))

    def limit(self, n: int) -> "DataFrame":
        return DataFrame(self._df.limit(n))

    def orderBy(self, *cols: Union[str, Column], ascending: Union[bool, List[bool]] = True) -> "DataFrame":
        exprs = []
        # Polars handles lists for descending
        is_descending = not ascending if isinstance(ascending, bool) else [not a for a in ascending]
        
        sort_cols = []
        for c in cols:
            if isinstance(c, str):
                sort_cols.append(c)
            elif isinstance(c, Column):
                sort_cols.append(c._expr)
        
        return DataFrame(self._df.sort(sort_cols, descending=is_descending))

    def groupBy(self, *cols: Union[str, Column]) -> "GroupedData":
        normalized_cols = []
        for c in cols:
            if isinstance(c, str):
                normalized_cols.append(c)
            elif isinstance(c, Column):
                normalized_cols.append(c._expr)
        return GroupedData(self._df.group_by(normalized_cols))

    def join(self, other: "DataFrame", on: Union[str, List[str], Column], how: str = "inner") -> "DataFrame":
        # Normalize join type literals
        h = how.lower().replace("_", "")
        how_map = {
            "inner": "inner", "left": "left", "leftouter": "left", "right": "right", "rightouter": "right",
            "full": "full", "outer": "full", "fullouter": "full", "semi": "semi", "leftsemi": "semi",
            "anti": "anti", "leftanti": "anti", "cross": "cross"
        }
        pl_how = how_map.get(h, "inner")

        if isinstance(on, Column):
            # Equi-join detection for performance and compatibility
            if getattr(on, "_is_equi_join_cond", False):
                l_match = (on._l_ref == id(self) or (self._alias and on._l_table == self._alias))
                r_match = (on._r_ref == id(other) or (other._alias and on._r_table == other._alias))
                
                if l_match and r_match:
                    if on._l_col == on._r_col:
                        res_df = self._df.join(other._df, left_on=on._l_col, right_on=on._r_col, how=pl_how)
                    else:
                        return self.join(other, on=[on._l_col, on._r_col], how=how)
                    res = DataFrame(res_df)
                    res._left_ref, res._right_ref = id(self), id(other)
                    res._left_alias, res._right_alias = self._alias, other._alias
                    res._left_cols, res._right_cols = self.columns, other.columns
                    return res

                
                # Check reversed
                l_match_rev = (on._l_ref == id(other) or (other._alias and on._l_table == other._alias))
                r_match_rev = (on._r_ref == id(self) or (self._alias and on._r_table == self._alias))
                if l_match_rev and r_match_rev:
                    if on._l_col == on._r_col:
                        res_df = self._df.join(other._df, left_on=on._r_col, right_on=on._l_col, how=pl_how)
                    else:
                        return self.join(other, on=[on._r_col, on._l_col], how=how)
                    res = DataFrame(res_df)
                    res._left_ref, res._right_ref = id(self), id(other)
                    res._left_alias, res._right_alias = self._alias, other._alias
                    res._left_cols, res._right_cols = self.columns, other.columns
                    return res


            # Non-equus: resolve predicates (apply _right suffixes where needed)
            resolved_expr = on._resolve(id(self), id(other), self._alias, other._alias, self.columns, other.columns)


            if pl_how == "inner":
                res = DataFrame(self._df.join_where(other._df, resolved_expr))
                res._left_ref, res._right_ref = id(self), id(other)
                res._left_alias, res._right_alias = self._alias, other._alias
                res._left_cols, res._right_cols = self.columns, other.columns
                return res

            
            # Non-equi fallback for other types
            left_id = "_left_idx"
            right_id = "_right_idx"
            df_left = self._df.with_row_index(left_id)
            df_right = other._df.with_row_index(right_id)
            matches = df_left.join_where(df_right, resolved_expr)
            matched_l = matches.get_column(left_id).unique()
            
            res_df = None
            if pl_how == "semi":
                res_df = df_left.filter(pl.col(left_id).is_in(matched_l)).drop(left_id)
            elif pl_how == "anti":
                res_df = df_left.filter(~pl.col(left_id).is_in(matched_l)).drop(left_id)
            elif pl_how == "left":
                unmatched = df_left.filter(~pl.col(left_id).is_in(matched_l))
                res_df = pl.concat([matches, unmatched], how="diagonal").drop([left_id, right_id])
            elif pl_how == "right":
                matched_r = matches.get_column(right_id).unique()
                unmatched = df_right.filter(~pl.col(right_id).is_in(matched_r))
                res_df = pl.concat([matches, unmatched], how="diagonal").drop([left_id, right_id])
            elif pl_how == "full":
                matched_r = matches.get_column(right_id).unique()
                unmatched_l = df_left.filter(~pl.col(left_id).is_in(matched_l))
                unmatched_r = df_right.filter(~pl.col(right_id).is_in(matched_r))
                res_df = pl.concat([matches, unmatched_l, unmatched_r], how="diagonal").drop([left_id, right_id])

            if res_df is not None:
                res = DataFrame(res_df)
                res._left_ref, res._right_ref = id(self), id(other)
                res._left_alias, res._right_alias = self._alias, other._alias
                res._left_cols, res._right_cols = self.columns, other.columns
                return res


            raise NotImplementedError(f"Join on Column expressions with '{how}' join is not yet supported.")

        # Resolve Column references in list
        if isinstance(on, list):
            exprs = []
            for c in on:
                if isinstance(c, Column):
                    if c._is_simple_col and (c._df_ref == id(other) or (other._alias and c._table_name == other._alias)):
                        exprs.append(pl.col(c._col_name + "_right"))
                    else:
                        exprs.append(c._expr)
                else:
                    exprs.append(c)
            on = exprs
            
        res_df = self._df.join(other._df, on=on, how=pl_how)
        res = DataFrame(res_df)
        res._left_ref, res._right_ref = id(self), id(other)
        res._left_alias, res._right_alias = self._alias, other._alias
        res._left_cols, res._right_cols = self.columns, other.columns
        return res







    def crossJoin(self, other: "DataFrame") -> "DataFrame":
        return DataFrame(self._df.join(other._df, how="cross"))

    def union(self, other: "DataFrame") -> "DataFrame":
        return DataFrame(pl.concat([self._df, other._df]))

    def unionByName(self, other: "DataFrame", allowMissingColumns: bool = False) -> "DataFrame":
        # Polars concat handles names by default if how='vertical'
        return DataFrame(pl.concat([self._df, other._df], how="vertical"))

    def show(self, n: int = 20, truncate: bool = True):




        print(self._df.head(n))

    def collect(self) -> List[Any]:
        return self._df.to_dicts()

    def count(self) -> int:
        return self._df.height

    @property
    def columns(self) -> List[str]:
        return self._df.columns

    def toPandas(self):
        return self._df.to_pandas()

    def alias(self, name: str) -> "DataFrame":
        new_df = DataFrame(self._df)
        new_df._alias = name
        return new_df

class GroupedData:

    def __init__(self, pl_groupby):
        self._gb = pl_groupby

    def agg(self, *exprs: Union[Column, List[Column]]) -> DataFrame:
        normalized_exprs = []
        for e in exprs:
            if isinstance(e, list):
                normalized_exprs.extend([i._expr for i in e])
            else:
                normalized_exprs.append(e._expr)
        
        return DataFrame(self._gb.agg(normalized_exprs))

    def count(self) -> DataFrame:
        return DataFrame(self._gb.count())

    def max(self) -> DataFrame:
        return DataFrame(self._gb.max())

    def min(self) -> DataFrame:
        return DataFrame(self._gb.min())

    def avg(self) -> DataFrame:
        return DataFrame(self._gb.mean())

    def sum(self) -> DataFrame:
        return DataFrame(self._gb.sum())

